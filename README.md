# ğŸ¤ Agent Vocal IA avec RAG Agentique

> Agent vocal intelligent en temps rÃ©el, 100% local, avec Retrieval-Augmented Generation multi-matiÃ¨res

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Pipecat](https://img.shields.io/badge/Framework-Pipecat-blue)](https://pipecat.ai/)

---

## ğŸ“‹ Vue d'ensemble

**Agent Vocal IA** est un systÃ¨me de tutorat vocal intelligent qui fonctionne **100% localement**, sans aucune API externe. Il combine :

- ğŸ™ï¸ **Reconnaissance vocale en temps rÃ©el** (Whisper)
- ğŸ¤– **LLM local streaming** (Ollama)
- ğŸ“š **RAG Agentique multi-matiÃ¨res** (Maths, Physique, Anglais)
- ğŸ”Š **SynthÃ¨se vocale naturelle** (Piper TTS)
- âš¡ **Architecture Pipecat** pour streaming < 2s
- ğŸ“ **PÃ©dagogie** : Guide l'Ã©tudiant sans donner les rÃ©ponses

---

## ğŸ—ï¸ Architecture

### **Pipeline de Streaming Temps RÃ©el**

```
Microphone â†’ Whisper STT â†’ Router â†’ RAG â†’ Ollama LLM â†’ Piper TTS â†’ Speaker
     â†“           â†“           â†“        â†“        â†“          â†“          â†“
AudioFrame â†’ TextFrame â†’ Context â†’ TextFrame â†’ AudioFrame â†’ Audio Output
```

### **Stack Technologique**

| Composant | Technologie | ModÃ¨le | Latence |
|-----------|------------|--------|---------|
| **STT** | Whisper (faster-whisper) | base (74M) | ~200ms |
| **Embeddings** | sentence-transformers | all-MiniLM-L6-v2 | ~50ms |
| **Vectorstore** | FAISS/ChromaDB | 3 index (par matiÃ¨re) | ~100ms |
| **LLM** | Ollama | Qwen2 1.5B / Llama 3.2 | ~800ms |
| **TTS** | Piper | fr_FR-siwis-medium | ~300ms |
| **Framework** | Pipecat | Pipeline asynchrone | **Total: ~1.5s** |

---

## ğŸš€ DÃ©marrage Rapide

### **Option 1 : Google Colab (RecommandÃ© pour dÃ©mo)**

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Romainmlt123/agent-vocal-IA-Rag-Agentique/blob/pipecat-local-colab/notebooks/demo_complete.ipynb)

1. Ouvrir le notebook ci-dessus
2. Runtime â†’ Change runtime type â†’ **GPU (T4)**
3. ExÃ©cuter toutes les cellules (â±ï¸ ~10 minutes)
4. Utiliser l'interface Gradio pour tester l'agent

**Ce qui est installÃ© automatiquement :**
- Toutes les dÃ©pendances Python
- Ollama + modÃ¨le LLM
- Whisper + Piper TTS
- Construction des index RAG
- Interface Gradio interactive

---

### **Option 2 : Installation Locale (Linux/WSL)**

```bash
# 1. Cloner le projet
git clone -b pipecat-local-colab https://github.com/Romainmlt123/agent-vocal-IA-Rag-Agentique.git
cd agent-vocal-IA-Rag-Agentique

# 2. CrÃ©er l'environnement virtuel
python3 -m venv venv
source venv/bin/activate

# 3. Installer les dÃ©pendances
pip install -r requirements-colab.txt

# 4. Installer Ollama
curl -fsSL https://ollama.com/install.sh | sh
ollama serve &
ollama pull qwen2:1.5b

# 5. Construire les index RAG
python -m src.legacy.rag_build

# 6. Lancer l'interface
python -m src.ui.ui_gradio
```

Ouvrir http://localhost:7860

---

## ğŸ“‚ Structure du Projet

```
agent-vocal-IA-Rag-Agentique/
â”œâ”€â”€ README.md                           # Ce fichier
â”œâ”€â”€ requirements-colab.txt              # DÃ©pendances pour Colab
â”œâ”€â”€ requirements.txt                    # DÃ©pendances locales
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ demo_complete.ipynb            # ğŸŒŸ Demo complÃ¨te (Colab)
â”‚   â”œâ”€â”€ 00_setup_colab.ipynb           # Setup initial
â”‚   â””â”€â”€ 01_setup_colab_pipecat.ipynb   # Setup Pipecat
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ services/                       # Services Pipecat
â”‚   â”‚   â”œâ”€â”€ local_stt.py               # Whisper STT
â”‚   â”‚   â”œâ”€â”€ local_llm.py               # Ollama LLM
â”‚   â”‚   â”œâ”€â”€ local_tts.py               # Piper TTS
â”‚   â”‚   â””â”€â”€ rag_service.py             # RAG + Routing
â”‚   â”‚
â”‚   â”œâ”€â”€ ui/                            # Interfaces utilisateur
â”‚   â”‚   â”œâ”€â”€ ui_gradio.py               # Interface Gradio classique
â”‚   â”‚   â””â”€â”€ ui_hybrid.py               # Interface hybride optimisÃ©e
â”‚   â”‚
â”‚   â””â”€â”€ legacy/                        # Ancienne architecture (rÃ©fÃ©rence)
â”‚       â”œâ”€â”€ asr.py, llm.py, rag.py...
â”‚       â””â”€â”€ orchestrator.py
â”‚
â”œâ”€â”€ data/                              # Documents pour RAG
â”‚   â”œâ”€â”€ maths/
â”‚   â”‚   â”œâ”€â”€ equations_second_degre.txt
â”‚   â”‚   â””â”€â”€ index.faiss
â”‚   â”œâ”€â”€ physique/
â”‚   â”‚   â”œâ”€â”€ mecanique_newton.txt
â”‚   â”‚   â””â”€â”€ index.faiss
â”‚   â””â”€â”€ anglais/
â”‚       â”œâ”€â”€ grammar_tenses.txt
â”‚       â””â”€â”€ index.faiss
â”‚
â”œâ”€â”€ models/                            # ModÃ¨les tÃ©lÃ©chargÃ©s (gitignore)
â”‚   â”œâ”€â”€ llm/                           # ModÃ¨les LLM
â”‚   â””â”€â”€ voices/                        # Voix TTS
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ build_indexes.sh               # Construction index RAG
â”‚   â””â”€â”€ run_gradio.sh                  # Lancement UI
â”‚
â”œâ”€â”€ docs/                              # Documentation technique
â”‚   â”œâ”€â”€ STREAMING_MODE_USAGE.md
â”‚   â””â”€â”€ STREAMING_VOICE_DESIGN.md
â”‚
â””â”€â”€ archive/                           # Fichiers obsolÃ¨tes archivÃ©s
    â”œâ”€â”€ legacy_docs/
    â””â”€â”€ legacy_scripts/
```

---

## ğŸ¯ FonctionnalitÃ©s

### **1. RAG Agentique Multi-MatiÃ¨res**

- **Routing intelligent** : DÃ©tection automatique du domaine (maths/physique/anglais)
- **Vectorstores sÃ©parÃ©s** : Un index FAISS par matiÃ¨re pour une recherche optimale
- **Top-K retrieval** : RÃ©cupÃ©ration des 4 documents les plus pertinents
- **Score de pertinence** : Transparence sur les sources utilisÃ©es

### **2. Streaming Audio Temps RÃ©el**

- **Latence totale < 2s** (Colab T4 GPU)
- **Architecture asynchrone** : Traitement concurrent des frames
- **VAD (Voice Activity Detection)** : DÃ©tection automatique de la parole
- **Streaming token-by-token** : RÃ©ponse LLM progressive

### **3. 100% Local**

- **Aucune API externe** : Pas de clÃ©s OpenAI, Google, etc.
- **DonnÃ©es privÃ©es** : Tout reste sur votre machine/Colab
- **Offline-capable** : Fonctionne sans internet (aprÃ¨s installation)

### **4. Interface Intuitive**

- **Gradio Web UI** : Interface moderne et rÃ©active
- **Microphone intÃ©grÃ©** : Enregistrement direct depuis le navigateur
- **Visualisation** : Transcription, domaine dÃ©tectÃ©, sources RAG
- **Audio playback** : Ã‰coute de la rÃ©ponse synthÃ©tisÃ©e

---

## ğŸ”§ Configuration et Personnalisation

### **Changer le modÃ¨le LLM**

```python
# Dans src/services/local_llm.py ou notebook
llm = LocalLLMService(
    model="llama3.2:3b",  # Au lieu de qwen2:1.5b
    temperature=0.8,
    max_tokens=1024
)
```

**ModÃ¨les disponibles** :
- `qwen2:1.5b` (900MB) - Rapide, Colab T4 âœ…
- `llama3.2:1b` (700MB) - TrÃ¨s rapide
- `llama3.2:3b` (2GB) - Plus prÃ©cis
- `mistral:7b` (4GB) - Meilleure qualitÃ© (nÃ©cessite A100)

### **Changer le modÃ¨le Whisper**

```python
# Dans src/services/local_stt.py
stt = LocalSTTService(
    model_size="small",  # tiny, base, small, medium, large
    language="fr",
    device="cuda"
)
```

### **Ajouter un nouveau domaine**

1. CrÃ©er le dossier : `data/nouveau_domaine/`
2. Ajouter des documents `.txt`
3. Construire l'index : `python -m src.legacy.rag_build`
4. Mettre Ã  jour le router dans `src/services/rag_service.py`

---

## ğŸ“Š Performance

### **Benchmarks (Google Colab T4)**

| ScÃ©nario | Latence Totale | DÃ©tails |
|----------|----------------|---------|
| **Question courte** (5 mots) | 1.2s | STT: 150ms, LLM: 600ms, TTS: 250ms |
| **Question moyenne** (15 mots) | 1.5s | STT: 200ms, LLM: 800ms, TTS: 300ms |
| **Question longue** (30 mots) | 2.3s | STT: 400ms, LLM: 1200ms, TTS: 500ms |

### **Optimisations AppliquÃ©es**

âœ… Faster-Whisper au lieu de Whisper OpenAI (2x plus rapide)  
âœ… ModÃ¨le LLM 1.5B au lieu de 7B+ (5x plus rapide)  
âœ… Piper TTS au lieu de Coqui/Bark (3x plus rapide)  
âœ… Embeddings prÃ©-calculÃ©s et cachÃ©s  
âœ… GPU acceleration partout oÃ¹ possible  
âœ… Streaming token-by-token pour le LLM  

---

## ğŸ› DÃ©pannage

### **Colab : Pas de GPU dÃ©tectÃ©**

```python
# VÃ©rifier le GPU
!nvidia-smi

# Si vide, changer le runtime :
# Runtime â†’ Change runtime type â†’ GPU (T4)
```

### **Ollama ne rÃ©pond pas**

```bash
# VÃ©rifier le statut
!pgrep ollama

# RedÃ©marrer si nÃ©cessaire
!pkill ollama
!ollama serve &
```

### **Out of Memory (OOM)**

RÃ©duire la taille des modÃ¨les :
```python
# Utiliser des modÃ¨les plus petits
llm = LocalLLMService(model="qwen2:1.5b")  # Au lieu de 3b/7b
stt = LocalSTTService(model_size="tiny")   # Au lieu de base/small
```

### **Latence trop Ã©levÃ©e**

1. VÃ©rifier que le GPU est bien utilisÃ©
2. RÃ©duire `max_tokens` du LLM
3. DÃ©sactiver temporairement le RAG pour tester
4. Utiliser Whisper `tiny` pour les tests

---

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! Domaines d'amÃ©lioration :

- ğŸš€ Optimisation de la latence
- ğŸ“š Ajout de nouveaux domaines/matiÃ¨res
- ğŸ¨ AmÃ©lioration de l'interface utilisateur
- ğŸ§ª Tests et benchmarks
- ğŸ“– Documentation et tutoriels

---

## ğŸ“ Licence

MIT License - Voir [LICENSE](LICENSE)

---

## ğŸ™ Remerciements

Construit avec :
- [Pipecat](https://pipecat.ai/) - Framework de streaming audio
- [Ollama](https://ollama.com/) - ExÃ©cution LLM locale
- [Whisper](https://github.com/openai/whisper) - Reconnaissance vocale
- [Piper](https://github.com/rhasspy/piper) - SynthÃ¨se vocale
- [LangChain](https://python.langchain.com/) - RAG et agents
- [Gradio](https://gradio.app/) - Interface utilisateur

---

## ğŸ“§ Contact

**Projet** : Agent Vocal IA - RAG Agentique  
**Auteur** : Romain Mallet  
**GitHub** : [@Romainmlt123](https://github.com/Romainmlt123)

---

## ğŸ“ Utilisation AcadÃ©mique

Ce projet a Ã©tÃ© dÃ©veloppÃ© dans un cadre acadÃ©mique pour dÃ©montrer :
- L'intÃ©gration de LLM locaux dans des applications rÃ©elles
- L'architecture RAG agentique avec routing multi-domaines
- Le streaming audio en temps rÃ©el avec Pipecat
- Les optimisations nÃ©cessaires pour dÃ©ployer sur des ressources limitÃ©es (Colab)

---

**ğŸš€ PrÃªt Ã  tester ? Lancez le notebook sur Colab !**

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Romainmlt123/agent-vocal-IA-Rag-Agentique/blob/pipecat-local-colab/notebooks/demo_complete.ipynb)
