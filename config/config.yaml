# ASR - Automatic Speech Recognition
asr:
  model: "base"  # Options: tiny, base, small, medium, large
  language: "fr"  # Primary language: fr, en
  device: "auto"  # auto, cpu, cuda
  compute_type: "int8"  # int8, float16, float32
  vad_threshold: 0.5  # Silero VAD threshold (0.0-1.0)
  vad_min_speech_duration_ms: 250
  vad_min_silence_duration_ms: 500

# RAG - Retrieval Augmented Generation
rag:
  chunk_size: 512  # Characters per chunk
  chunk_overlap: 50  # Overlap between chunks
  top_k: 4  # Number of passages to retrieve
  embedding_model: "sentence-transformers/all-MiniLM-L6-v2"
  embedding_device: "cpu"
  similarity_threshold: 0.3  # Minimum similarity score
  
  # Subject-specific index paths
  indexes:
    maths: "data/maths/index.faiss"
    physique: "data/physique/index.faiss"
    anglais: "data/anglais/index.faiss"

# LLM - Large Language Model
llm:
  # Model paths per subject (GGUF format)
  models:
    maths: "models/llm/Phi-3-mini-4k-instruct-q4.gguf"
    physique: "models/llm/Phi-3-mini-4k-instruct-q4.gguf"
    anglais: "models/llm/Phi-3-mini-4k-instruct-q4.gguf"
    default: "models/llm/Phi-3-mini-4k-instruct-q4.gguf"
  
  # Generation parameters
  n_ctx: 4096  # Context window size
  n_threads: 4  # CPU threads
  temperature: 0.7
  top_p: 0.9
  top_k: 40
  repeat_penalty: 1.1
  max_tokens: 512
  stream: true
  
  # Prompt templates
  system_prompt: |
    You are a patient and pedagogical tutor. Your role is to guide students 
    to understand concepts through hints, never giving direct solutions.
    Always provide exactly 3 levels of hints:
    1. Conceptual hint (high-level)
    2. Strategic hint (method/approach)
    3. Detailed hint (step-by-step guidance)
    
    Use the provided context to ensure accuracy. Cite sources when relevant.

# TTS - Text to Speech
tts:
  voices:
    fr: "models/voices/fr_FR-siwis-medium.onnx"
    en: "models/voices/en_US-lessac-medium.onnx"
  speed: 1.0
  noise_scale: 0.667
  noise_w: 0.8
  sample_rate: 22050

# Router - Subject and Model Router
router:
  # Keyword-based subject detection
  keywords:
    maths:
      - "mathématiques"
      - "math"
      - "maths"
      - "algèbre"
      - "géométrie"
      - "calcul"
      - "équation"
      - "fonction"
      - "dérivée"
      - "intégrale"
      - "probabilité"
      - "statistique"
      - "résoudre"
      - "résolution"
      - "racine"
      - "discriminant"
      - "trinôme"
      - "polynôme"
      - "x²"
      - "carré"
    physique:
      - "physique"
      - "physics"
      - "mécanique"
      - "énergie"
      - "force"
      - "vitesse"
      - "accélération"
      - "électricité"
      - "magnétisme"
      - "optique"
      - "thermodynamique"
      - "newton"
      - "loi"
      - "mouvement"
      - "masse"
    anglais:
      - "anglais"
      - "english"
      - "grammar"
      - "vocabulary"
      - "grammaire"
      - "vocabulaire"
      - "conjugaison"
      - "orthographe"
      - "tense"
      - "tenses"
      - "temps"
      - "present"
      - "past"
      - "future"
      - "perfect"
      - "simple"
  
  # Fallback to TF-IDF if keyword detection fails
  use_tfidf_fallback: true
  tfidf_top_n: 3

# Orchestrator
orchestrator:
  max_session_duration_seconds: 3600  # 1 hour
  max_retries: 3
  timeout_seconds: 30
  enable_logging: true
  log_level: "INFO"  # DEBUG, INFO, WARNING, ERROR

# UI - Gradio Interface
ui:
  server_name: "0.0.0.0"
  server_port: 7860
  share: false  # Set true for Colab public link
  enable_queue: true
  max_file_size_mb: 10
  theme: "default"
  
  # Push-to-talk settings
  audio_chunk_duration_ms: 500
  show_transcript_live: true
  show_rag_sources: true
  show_hint_ladder: true

# Logging
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "logs/agent_vocal.log"
  max_bytes: 10485760  # 10MB
  backup_count: 5

# Paths
paths:
  data_dir: "data"
  models_dir: "models"
  logs_dir: "logs"
  cache_dir: ".cache"
