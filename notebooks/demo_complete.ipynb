{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c280bca",
   "metadata": {},
   "source": [
    "# ğŸ¤ Agent Vocal IA avec RAG Agentique - DÃ©mo ComplÃ¨te\n",
    "## 100% Local | Temps RÃ©el | Google Colab\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ“‹ Vue d'ensemble du projet\n",
    "\n",
    "Ce notebook prÃ©sente un **agent vocal IA intelligent** capable de :\n",
    "- ğŸ™ï¸ **Reconnaissance vocale en temps rÃ©el** (Whisper)\n",
    "- ğŸ¤– **GÃ©nÃ©ration de rÃ©ponses intelligentes** (Ollama + LLM local)\n",
    "- ğŸ“š **RAG Agentique** (Retrieval-Augmented Generation avec routage multi-domaines)\n",
    "- ğŸ”Š **SynthÃ¨se vocale naturelle** (Piper TTS)\n",
    "- âš¡ **Architecture streaming** (Pipecat framework)\n",
    "\n",
    "### ğŸ¯ Domaines supportÃ©s\n",
    "- **MathÃ©matiques** : Ã‰quations, algÃ¨bre, gÃ©omÃ©trie\n",
    "- **Physique** : MÃ©canique, optique, Ã©lectricitÃ©\n",
    "- **Anglais** : Grammaire, conjugaison, vocabulaire\n",
    "\n",
    "### ğŸ—ï¸ Architecture\n",
    "```\n",
    "Microphone â†’ Whisper STT â†’ Router â†’ RAG â†’ Ollama LLM â†’ Piper TTS â†’ Audio Output\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**âš ï¸ Important** : Assurez-vous d'avoir activÃ© le GPU dans :\n",
    "`Runtime â†’ Change runtime type â†’ Hardware accelerator â†’ GPU (T4)`\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ“Š Temps estimÃ© d'exÃ©cution** : ~10 minutes pour l'installation complÃ¨te"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f5eb7a",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Ã‰tape 1 : Installation des DÃ©pendances\n",
    "\n",
    "Cette cellule installe tous les packages nÃ©cessaires. DurÃ©e : ~5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1422e225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "print(\"ğŸš€ Installation des dÃ©pendances systÃ¨me...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# VÃ©rifier si on est sur Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IS_COLAB = True\n",
    "    print(\"âœ… Environnement dÃ©tectÃ© : Google Colab\")\n",
    "except:\n",
    "    IS_COLAB = False\n",
    "    print(\"âœ… Environnement dÃ©tectÃ© : Local/autre\")\n",
    "\n",
    "# Installation des dÃ©pendances systÃ¨me\n",
    "if IS_COLAB:\n",
    "    !apt-get update -qq\n",
    "    !apt-get install -y -qq portaudio19-dev python3-pyaudio ffmpeg espeak-ng > /dev/null 2>&1\n",
    "    print(\"âœ… DÃ©pendances systÃ¨me installÃ©es\")\n",
    "\n",
    "# Installation des packages Python\n",
    "print(\"\\nğŸ“¦ Installation des packages Python...\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "packages = [\n",
    "    \"pipecat-ai\",\n",
    "    \"torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\",\n",
    "    \"openai-whisper\",\n",
    "    \"faster-whisper\",\n",
    "    \"langchain\",\n",
    "    \"langchain-community\",\n",
    "    \"chromadb\",\n",
    "    \"sentence-transformers\",\n",
    "    \"faiss-cpu\",\n",
    "    \"sounddevice\",\n",
    "    \"soundfile\",\n",
    "    \"gradio\",\n",
    "    \"nest-asyncio\",\n",
    "    \"llama-cpp-python\",\n",
    "    \"pydub\"\n",
    "]\n",
    "\n",
    "for i, package in enumerate(packages, 1):\n",
    "    print(f\"[{i}/{len(packages)}] Installation de {package.split()[0]}...\")\n",
    "    subprocess.run(f\"{sys.executable} -m pip install -q {package}\", shell=True, check=True)\n",
    "\n",
    "print(\"\\nâœ… Toutes les dÃ©pendances sont installÃ©es!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3136902b",
   "metadata": {},
   "source": [
    "## ğŸ” Ã‰tape 2 : VÃ©rification du GPU\n",
    "\n",
    "VÃ©rifions que le GPU est bien disponible pour accÃ©lÃ©rer les modÃ¨les."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5641979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(\"ğŸ” VÃ©rification du matÃ©riel...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# VÃ©rifier CUDA\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"âœ… GPU disponible : {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   MÃ©moire GPU : {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    DEVICE = \"cuda\"\n",
    "else:\n",
    "    print(\"âš ï¸  Pas de GPU dÃ©tectÃ© - utilisation du CPU (plus lent)\")\n",
    "    DEVICE = \"cpu\"\n",
    "\n",
    "print(f\"\\nğŸ¯ Device utilisÃ© : {DEVICE}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d048a2a",
   "metadata": {},
   "source": [
    "## ğŸ“¥ Ã‰tape 3 : Clonage du Projet\n",
    "\n",
    "TÃ©lÃ©chargement du code source depuis GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a0af3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(\"ğŸ“¥ Clonage du projet depuis GitHub...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Nettoyer si existe dÃ©jÃ \n",
    "if os.path.exists(\"intelligence_lab_agent_vocal\"):\n",
    "    !rm -rf intelligence_lab_agent_vocal\n",
    "    print(\"ğŸ§¹ Ancien dossier supprimÃ©\")\n",
    "\n",
    "# Cloner le repo\n",
    "!git clone -b pipecat-local-colab https://github.com/Romainmlt123/agent-vocal-IA-Rag-Agentique.git intelligence_lab_agent_vocal\n",
    "\n",
    "# Se dÃ©placer dans le dossier\n",
    "os.chdir(\"intelligence_lab_agent_vocal\")\n",
    "\n",
    "print(\"\\nâœ… Projet clonÃ© avec succÃ¨s!\")\n",
    "print(f\"ğŸ“ Dossier actuel : {os.getcwd()}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3866dca2",
   "metadata": {},
   "source": [
    "## ğŸ¤– Ã‰tape 4 : Installation d'Ollama et tÃ©lÃ©chargement du modÃ¨le LLM\n",
    "\n",
    "Ollama permet d'exÃ©cuter des LLM localement. Nous utiliserons Llama 3.2 (1B) optimisÃ© pour Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1107866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "print(\"ğŸ¤– Installation d'Ollama...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Installer Ollama\n",
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "# DÃ©marrer le serveur Ollama en arriÃ¨re-plan\n",
    "print(\"\\nğŸš€ DÃ©marrage du serveur Ollama...\")\n",
    "ollama_process = subprocess.Popen(\n",
    "    ['ollama', 'serve'],\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.PIPE\n",
    ")\n",
    "time.sleep(5)  # Attendre le dÃ©marrage\n",
    "\n",
    "print(\"âœ… Serveur Ollama dÃ©marrÃ©\")\n",
    "\n",
    "# TÃ©lÃ©charger le modÃ¨le (version lÃ©gÃ¨re pour Colab)\n",
    "print(\"\\nğŸ“¥ TÃ©lÃ©chargement du modÃ¨le Qwen2 1.5B...\")\n",
    "print(\"   (OptimisÃ© pour Colab, ~900MB)\")\n",
    "!ollama pull qwen2:1.5b\n",
    "\n",
    "print(\"\\nâœ… ModÃ¨le LLM prÃªt!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87352ac0",
   "metadata": {},
   "source": [
    "## ğŸ™ï¸ Ã‰tape 5 : TÃ©lÃ©chargement du modÃ¨le Whisper (STT)\n",
    "\n",
    "Whisper permet la reconnaissance vocale en temps rÃ©el."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e9108b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "\n",
    "print(\"ğŸ™ï¸ TÃ©lÃ©chargement du modÃ¨le Whisper...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# TÃ©lÃ©charger le modÃ¨le (base = bon compromis)\n",
    "whisper_model = WhisperModel(\"base\", device=DEVICE, compute_type=\"float16\" if DEVICE == \"cuda\" else \"int8\")\n",
    "\n",
    "print(\"âœ… ModÃ¨le Whisper prÃªt!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3da111",
   "metadata": {},
   "source": [
    "## ğŸ“š Ã‰tape 6 : Construction des index RAG\n",
    "\n",
    "Construction des index vectoriels pour les documents de mathÃ©matiques, physique et anglais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e739f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/intelligence_lab_agent_vocal')\n",
    "\n",
    "print(\"ğŸ“š Construction des index RAG...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Construire les index pour chaque domaine en utilisant le script legacy\n",
    "import subprocess\n",
    "result = subprocess.run(\n",
    "    [sys.executable, \"-m\", \"src.legacy.rag_build\"],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(result.stdout)\n",
    "    print(\"\\nâœ… Index RAG construits!\")\n",
    "    print(\"   - data/maths/index.faiss\")\n",
    "    print(\"   - data/physique/index.faiss\") \n",
    "    print(\"   - data/anglais/index.faiss\")\n",
    "else:\n",
    "    print(\"âš ï¸ Erreur lors de la construction:\")\n",
    "    print(result.stderr)\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4204dae8",
   "metadata": {},
   "source": [
    "## ğŸ¨ Ã‰tape 7 : Initialisation des composants\n",
    "\n",
    "Chargement de tous les modules : Router, RAG, LLM, ASR, TTS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c67992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pipeline.voice_pipeline import create_voice_pipeline\n",
    "import asyncio\n",
    "\n",
    "print(\"ğŸ¨ Initialisation du Pipeline Pipecat...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# CrÃ©er le pipeline orchestrateur avec tous les services intÃ©grÃ©s\n",
    "print(\"\ude80 CrÃ©ation du Voice Pipeline Orchestrator...\")\n",
    "pipeline = await create_voice_pipeline(\n",
    "    stt_model_size=\"base\",\n",
    "    llm_model=\"qwen2:1.5b\",\n",
    "    tts_voice=\"fr_FR-siwis-medium\",\n",
    "    rag_top_k=4,\n",
    "    enable_metrics=True\n",
    ")\n",
    "\n",
    "print(\"\\nâœ… Pipeline Pipecat complÃ¨tement configurÃ©!\")\n",
    "print(\"\udcca Architecture : Audio â†’ Whisper â†’ RAG â†’ Ollama â†’ Piper â†’ Audio\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nğŸ¯ Composants du pipeline:\")\n",
    "print(f\"  â€¢ STT: Whisper {pipeline.stt_model_size}\")\n",
    "print(f\"  â€¢ LLM: {pipeline.llm_model}\")\n",
    "print(f\"  â€¢ TTS: {pipeline.tts_voice}\")\n",
    "print(f\"  â€¢ RAG: Top-{pipeline.rag_top_k} retrieval\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beea61df",
   "metadata": {},
   "source": [
    "## ğŸ­ Ã‰tape 8 : Interface Gradio - DÃ©mo Interactive\n",
    "\n",
    "Interface permettant au jury de tester l'agent vocal en direct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c581d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "\n",
    "def process_audio(audio_input):\n",
    "    \"\"\"\n",
    "    Traite l'audio enregistrÃ© et retourne la rÃ©ponse de l'agent\n",
    "    \n",
    "    Args:\n",
    "        audio_input: tuple (sample_rate, audio_data) depuis Gradio\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (transcription, sujet, rÃ©ponse_texte, audio_sortie, sources)\n",
    "    \"\"\"\n",
    "    if audio_input is None:\n",
    "        return \"âŒ Aucun audio enregistrÃ©\", \"\", \"\", None, \"\"\n",
    "    \n",
    "    try:\n",
    "        # Extraire les donnÃ©es\n",
    "        sample_rate, audio_data = audio_input\n",
    "        \n",
    "        # Si stereo, convertir en mono\n",
    "        if len(audio_data.shape) > 1:\n",
    "            audio_data = audio_data.mean(axis=1)\n",
    "        \n",
    "        # Normaliser\n",
    "        audio_data = audio_data.astype(np.float32)\n",
    "        if audio_data.max() > 1.0:\n",
    "            audio_data = audio_data / 32768.0\n",
    "        \n",
    "        # Traiter avec l'orchestrator\n",
    "        result = orchestrator.process_question(audio_data, sample_rate)\n",
    "        \n",
    "        # Formater les sources\n",
    "        sources_text = \"\\n\\n\".join([\n",
    "            f\"ğŸ“„ **{src['title']}** (score: {src['score']:.2f})\\n{src['content'][:200]}...\"\n",
    "            for src in result.get('sources', [])\n",
    "        ])\n",
    "        \n",
    "        return (\n",
    "            result['transcription'],\n",
    "            result['subject'],\n",
    "            result['response'],\n",
    "            (result['sample_rate'], result['audio']),\n",
    "            sources_text or \"Aucune source utilisÃ©e\"\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"âŒ Erreur: {str(e)}\", \"\", \"\", None, \"\"\n",
    "\n",
    "\n",
    "# CrÃ©er l'interface\n",
    "with gr.Blocks(title=\"ğŸ¤ Agent Vocal IA - RAG Agentique\", theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # ğŸ¤ Agent Vocal IA avec RAG Agentique\n",
    "    ### 100% Local | Temps RÃ©el | Multi-Domaines\n",
    "    \n",
    "    **Instructions** :\n",
    "    1. Cliquez sur le microphone ğŸ¤ pour enregistrer votre question\n",
    "    2. Parlez clairement (franÃ§ais)\n",
    "    3. Attendez la transcription et la rÃ©ponse de l'IA\n",
    "    4. Ã‰coutez la rÃ©ponse audio gÃ©nÃ©rÃ©e ğŸ”Š\n",
    "    \n",
    "    **Domaines supportÃ©s** : MathÃ©matiques ğŸ§® | Physique âš›ï¸ | Anglais ğŸ‡¬ğŸ‡§\n",
    "    \"\"\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            # Input\n",
    "            audio_input = gr.Audio(\n",
    "                sources=[\"microphone\"],\n",
    "                type=\"numpy\",\n",
    "                label=\"ğŸ™ï¸ Enregistrez votre question\"\n",
    "            )\n",
    "            submit_btn = gr.Button(\"ğŸš€ Traiter\", variant=\"primary\", size=\"lg\")\n",
    "            \n",
    "        with gr.Column(scale=1):\n",
    "            # Outputs\n",
    "            transcription_out = gr.Textbox(\n",
    "                label=\"ğŸ“ Transcription\",\n",
    "                lines=2,\n",
    "                interactive=False\n",
    "            )\n",
    "            subject_out = gr.Textbox(\n",
    "                label=\"ğŸ¯ Domaine dÃ©tectÃ©\",\n",
    "                interactive=False\n",
    "            )\n",
    "            response_out = gr.Textbox(\n",
    "                label=\"ğŸ’¡ RÃ©ponse de l'IA\",\n",
    "                lines=5,\n",
    "                interactive=False\n",
    "            )\n",
    "            audio_output = gr.Audio(\n",
    "                label=\"ğŸ”Š RÃ©ponse audio\",\n",
    "                type=\"numpy\"\n",
    "            )\n",
    "    \n",
    "    with gr.Accordion(\"ğŸ“š Sources RAG utilisÃ©es\", open=False):\n",
    "        sources_out = gr.Markdown()\n",
    "    \n",
    "    # Exemples\n",
    "    gr.Markdown(\"### ğŸ’¡ Exemples de questions\")\n",
    "    gr.Examples(\n",
    "        examples=[\n",
    "            \"Comment rÃ©soudre une Ã©quation du second degrÃ© ?\",\n",
    "            \"Qu'est-ce que la loi de Newton ?\",\n",
    "            \"Comment conjuguer le verbe to be au prÃ©sent ?\"\n",
    "        ],\n",
    "        inputs=None,\n",
    "        label=\"Cliquez pour copier une question exemple\"\n",
    "    )\n",
    "    \n",
    "    # Event\n",
    "    submit_btn.click(\n",
    "        fn=process_audio,\n",
    "        inputs=[audio_input],\n",
    "        outputs=[transcription_out, subject_out, response_out, audio_output, sources_out]\n",
    "    )\n",
    "\n",
    "print(\"âœ… Interface Gradio crÃ©Ã©e!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42ea248",
   "metadata": {},
   "source": [
    "## ğŸš€ Ã‰tape 9 : Lancement de l'Application\n",
    "\n",
    "Lancez l'interface Gradio et testez l'agent vocal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4a292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸš€ Lancement de l'application...\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nğŸ“± L'interface va s'ouvrir dans quelques secondes...\")\n",
    "print(\"ğŸ’¡ Utilisez le microphone pour poser vos questions!\")\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "# Lancer l'application\n",
    "demo.launch(\n",
    "    share=True,  # CrÃ©er un lien public partageable\n",
    "    debug=True,\n",
    "    show_error=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
