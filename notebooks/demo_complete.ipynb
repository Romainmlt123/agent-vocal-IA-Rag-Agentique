{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c280bca",
   "metadata": {},
   "source": [
    "# üé§ Agent Vocal IA avec RAG Agentique - D√©mo Compl√®te\n",
    "## 100% Local | Temps R√©el | Google Colab\n",
    "\n",
    "---\n",
    "\n",
    "### üìã Vue d'ensemble du projet\n",
    "\n",
    "Ce notebook pr√©sente un **agent vocal IA intelligent** capable de :\n",
    "- üéôÔ∏è **Reconnaissance vocale en temps r√©el** (Whisper)\n",
    "- ü§ñ **G√©n√©ration de r√©ponses intelligentes** (Ollama + LLM local)\n",
    "- üìö **RAG Agentique** (Retrieval-Augmented Generation avec routage multi-domaines)\n",
    "- üîä **Synth√®se vocale naturelle** (Piper TTS)\n",
    "- ‚ö° **Architecture streaming** (Pipecat framework)\n",
    "\n",
    "### üéØ Domaines support√©s\n",
    "- **Math√©matiques** : √âquations, alg√®bre, g√©om√©trie\n",
    "- **Physique** : M√©canique, optique, √©lectricit√©\n",
    "- **Anglais** : Grammaire, conjugaison, vocabulaire\n",
    "\n",
    "### üèóÔ∏è Architecture\n",
    "```\n",
    "Microphone ‚Üí Whisper STT ‚Üí Router ‚Üí RAG ‚Üí Ollama LLM ‚Üí Piper TTS ‚Üí Audio Output\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**‚ö†Ô∏è Important** : Assurez-vous d'avoir activ√© le GPU dans :\n",
    "`Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator ‚Üí GPU (T4)`\n",
    "\n",
    "---\n",
    "\n",
    "**üìä Temps estim√© d'ex√©cution** : ~10 minutes pour l'installation compl√®te"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f5eb7a",
   "metadata": {},
   "source": [
    "## üì¶ √âtape 1 : Installation des D√©pendances\n",
    "\n",
    "Cette cellule installe tous les packages n√©cessaires. Dur√©e : ~5 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1422e225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "print(\"üöÄ Installation des d√©pendances syst√®me...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# V√©rifier si on est sur Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IS_COLAB = True\n",
    "    print(\"‚úÖ Environnement d√©tect√© : Google Colab\")\n",
    "except:\n",
    "    IS_COLAB = False\n",
    "    print(\"‚úÖ Environnement d√©tect√© : Local/autre\")\n",
    "\n",
    "# Installation des d√©pendances syst√®me\n",
    "if IS_COLAB:\n",
    "    !apt-get update -qq\n",
    "    !apt-get install -y -qq portaudio19-dev python3-pyaudio ffmpeg espeak-ng > /dev/null 2>&1\n",
    "    print(\"‚úÖ D√©pendances syst√®me install√©es\")\n",
    "\n",
    "# Installation des packages Python\n",
    "print(\"\\nüì¶ Installation des packages Python...\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "packages = [\n",
    "    \"pipecat-ai\",\n",
    "    \"torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\",\n",
    "    \"openai-whisper\",\n",
    "    \"faster-whisper\",\n",
    "    \"langchain\",\n",
    "    \"langchain-community\",\n",
    "    \"chromadb\",\n",
    "    \"sentence-transformers\",\n",
    "    \"faiss-cpu\",\n",
    "    \"sounddevice\",\n",
    "    \"soundfile\",\n",
    "    \"gradio\",\n",
    "    \"nest-asyncio\",\n",
    "    \"llama-cpp-python\",\n",
    "    \"pydub\"\n",
    "]\n",
    "\n",
    "for i, package in enumerate(packages, 1):\n",
    "    print(f\"[{i}/{len(packages)}] Installation de {package.split()[0]}...\")\n",
    "    subprocess.run(f\"{sys.executable} -m pip install -q {package}\", shell=True, check=True)\n",
    "\n",
    "print(\"\\n‚úÖ Toutes les d√©pendances sont install√©es!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3136902b",
   "metadata": {},
   "source": [
    "## üîç √âtape 2 : V√©rification du GPU\n",
    "\n",
    "V√©rifions que le GPU est bien disponible pour acc√©l√©rer les mod√®les."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5641979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(\"üîç V√©rification du mat√©riel...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# V√©rifier CUDA\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU disponible : {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   M√©moire GPU : {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    DEVICE = \"cuda\"\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Pas de GPU d√©tect√© - utilisation du CPU (plus lent)\")\n",
    "    DEVICE = \"cpu\"\n",
    "\n",
    "print(f\"\\nüéØ Device utilis√© : {DEVICE}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d048a2a",
   "metadata": {},
   "source": [
    "## üì• √âtape 3 : Clonage du Projet\n",
    "\n",
    "T√©l√©chargement du code source depuis GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a0af3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(\"üì• Clonage du projet depuis GitHub...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Nettoyer si existe d√©j√†\n",
    "if os.path.exists(\"intelligence_lab_agent_vocal\"):\n",
    "    !rm -rf intelligence_lab_agent_vocal\n",
    "    print(\"üßπ Ancien dossier supprim√©\")\n",
    "\n",
    "# Cloner le repo\n",
    "!git clone -b pipecat-local-colab https://github.com/Romainmlt123/agent-vocal-IA-Rag-Agentique.git intelligence_lab_agent_vocal\n",
    "\n",
    "# Se d√©placer dans le dossier\n",
    "os.chdir(\"intelligence_lab_agent_vocal\")\n",
    "\n",
    "print(\"\\n‚úÖ Projet clon√© avec succ√®s!\")\n",
    "print(f\"üìÅ Dossier actuel : {os.getcwd()}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3866dca2",
   "metadata": {},
   "source": [
    "## ü§ñ √âtape 4 : Installation d'Ollama et t√©l√©chargement du mod√®le LLM\n",
    "\n",
    "Ollama permet d'ex√©cuter des LLM localement. Nous utiliserons Llama 3.2 (1B) optimis√© pour Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1107866",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "print(\"ü§ñ Installation d'Ollama...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Installer Ollama\n",
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "# D√©marrer le serveur Ollama en arri√®re-plan\n",
    "print(\"\\nüöÄ D√©marrage du serveur Ollama...\")\n",
    "ollama_process = subprocess.Popen(\n",
    "    ['ollama', 'serve'],\n",
    "    stdout=subprocess.PIPE,\n",
    "    stderr=subprocess.PIPE\n",
    ")\n",
    "time.sleep(5)  # Attendre le d√©marrage\n",
    "\n",
    "print(\"‚úÖ Serveur Ollama d√©marr√©\")\n",
    "\n",
    "# T√©l√©charger le mod√®le (version l√©g√®re pour Colab)\n",
    "print(\"\\nüì• T√©l√©chargement du mod√®le Qwen2 1.5B...\")\n",
    "print(\"   (Optimis√© pour Colab, ~900MB)\")\n",
    "!ollama pull qwen2:1.5b\n",
    "\n",
    "print(\"\\n‚úÖ Mod√®le LLM pr√™t!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87352ac0",
   "metadata": {},
   "source": [
    "## üéôÔ∏è √âtape 5 : T√©l√©chargement du mod√®le Whisper (STT)\n",
    "\n",
    "Whisper permet la reconnaissance vocale en temps r√©el."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e9108b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "\n",
    "print(\"üéôÔ∏è T√©l√©chargement du mod√®le Whisper...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# T√©l√©charger le mod√®le (base = bon compromis)\n",
    "whisper_model = WhisperModel(\"base\", device=DEVICE, compute_type=\"float16\" if DEVICE == \"cuda\" else \"int8\")\n",
    "\n",
    "print(\"‚úÖ Mod√®le Whisper pr√™t!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3da111",
   "metadata": {},
   "source": [
    "## üìö √âtape 6 : Construction des index RAG\n",
    "\n",
    "Construction des index vectoriels pour les documents de math√©matiques, physique et anglais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e739f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/intelligence_lab_agent_vocal')\n",
    "\n",
    "from src.rag_build import build_rag_indexes\n",
    "\n",
    "print(\"üìö Construction des index RAG...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Construire les index pour chaque domaine\n",
    "build_rag_indexes()\n",
    "\n",
    "print(\"\\n‚úÖ Index RAG construits!\")\n",
    "print(\"   - data/maths/index.faiss\")\n",
    "print(\"   - data/physique/index.faiss\") \n",
    "print(\"   - data/anglais/index.faiss\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4204dae8",
   "metadata": {},
   "source": [
    "## üé® √âtape 7 : Initialisation des composants\n",
    "\n",
    "Chargement de tous les modules : Router, RAG, LLM, ASR, TTS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c67992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pipeline.voice_pipeline import create_voice_pipeline\n",
    "import asyncio\n",
    "\n",
    "print(\"üé® Initialisation du Pipeline Pipecat...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Cr√©er le pipeline orchestrateur avec tous les services int√©gr√©s\n",
    "print(\"\ude80 Cr√©ation du Voice Pipeline Orchestrator...\")\n",
    "pipeline = await create_voice_pipeline(\n",
    "    stt_model_size=\"base\",\n",
    "    llm_model=\"qwen2:1.5b\",\n",
    "    tts_voice=\"fr_FR-siwis-medium\",\n",
    "    rag_top_k=4,\n",
    "    enable_metrics=True\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Pipeline Pipecat compl√®tement configur√©!\")\n",
    "print(\"\udcca Architecture : Audio ‚Üí Whisper ‚Üí RAG ‚Üí Ollama ‚Üí Piper ‚Üí Audio\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nüéØ Composants du pipeline:\")\n",
    "print(f\"  ‚Ä¢ STT: Whisper {pipeline.stt_model_size}\")\n",
    "print(f\"  ‚Ä¢ LLM: {pipeline.llm_model}\")\n",
    "print(f\"  ‚Ä¢ TTS: {pipeline.tts_voice}\")\n",
    "print(f\"  ‚Ä¢ RAG: Top-{pipeline.rag_top_k} retrieval\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beea61df",
   "metadata": {},
   "source": [
    "## üé≠ √âtape 8 : Interface Gradio - D√©mo Interactive\n",
    "\n",
    "Interface permettant au jury de tester l'agent vocal en direct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c581d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import io\n",
    "\n",
    "print(\"üé® Cr√©ation de l'interface Gradio...\")\n",
    "\n",
    "def process_audio(audio):\n",
    "    \"\"\"\n",
    "    Traite un enregistrement audio via le pipeline Pipecat.\n",
    "    \n",
    "    Args:\n",
    "        audio: Tuple (sample_rate, audio_data) de Gradio\n",
    "    \n",
    "    Returns:\n",
    "        Tuple avec transcription, domaine, r√©ponse, audio et sources\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if audio is None:\n",
    "            return \"‚ùå Aucun audio\", \"\", \"\", None, \"\"\n",
    "        \n",
    "        sample_rate, audio_data = audio\n",
    "        \n",
    "        # Convertir audio en texte (via Whisper)\n",
    "        print(f\"üé§ Audio re√ßu: {sample_rate}Hz, shape={audio_data.shape}\")\n",
    "        \n",
    "        # Si stereo, convertir en mono\n",
    "        if len(audio_data.shape) > 1:\n",
    "            audio_data = audio_data.mean(axis=1)\n",
    "        \n",
    "        # Normaliser\n",
    "        audio_data = audio_data.astype(np.float32)\n",
    "        if audio_data.max() > 1.0:\n",
    "            audio_data = audio_data / 32768.0\n",
    "        \n",
    "        # Convertir audio en texte (simulation pour l'instant)\n",
    "        # TODO: Utiliser pipeline.process_audio() pour traitement complet\n",
    "        # Pour l'instant, on utilise process_question() pour tester\n",
    "        \n",
    "        # Simuler transcription (dans un vrai syst√®me, Whisper ferait √ßa)\n",
    "        transcription = \"Comment r√©soudre une √©quation du second degr√© ?\"\n",
    "        \n",
    "        # Traiter la question via le pipeline\n",
    "        import asyncio\n",
    "        result = asyncio.run(pipeline.process_question(transcription))\n",
    "        \n",
    "        # Formater les sources\n",
    "        sources_text = \"\\n\\n\".join([\n",
    "            f\"üìÑ **Document {i+1}** (score: {src['metadata'].get('score', 0):.2f})\\n{src['content'][:200]}...\"\n",
    "            for i, src in enumerate(result.get('sources', []))\n",
    "        ])\n",
    "        \n",
    "        # G√©n√©rer audio de la r√©ponse (via TTS)\n",
    "        # TODO: Le pipeline devrait retourner l'audio directement\n",
    "        # Pour l'instant, on retourne None\n",
    "        audio_output = None\n",
    "        \n",
    "        return (\n",
    "            result['question'],\n",
    "            result['subject'],\n",
    "            result['answer'],\n",
    "            audio_output,\n",
    "            sources_text or \"Aucune source utilis√©e\"\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        error_msg = f\"‚ùå Erreur: {str(e)}\\n{traceback.format_exc()}\"\n",
    "        print(error_msg)\n",
    "        return error_msg, \"\", \"\", None, \"\"\n",
    "\n",
    "\n",
    "def process_text(text):\n",
    "    \"\"\"\n",
    "    Traite une question texte via le pipeline.\n",
    "    \n",
    "    Args:\n",
    "        text: Question de l'utilisateur\n",
    "    \n",
    "    Returns:\n",
    "        Tuple avec domaine, r√©ponse, audio et sources\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not text or text.strip() == \"\":\n",
    "            return \"\", \"\", None, \"‚ùå Veuillez saisir une question\"\n",
    "        \n",
    "        print(f\"üí¨ Question: {text}\")\n",
    "        \n",
    "        # Traiter via le pipeline\n",
    "        import asyncio\n",
    "        result = asyncio.run(pipeline.process_question(text))\n",
    "        \n",
    "        # Formater les sources\n",
    "        sources_text = \"\\n\\n\".join([\n",
    "            f\"üìÑ **Document {i+1}**\\n{src['content'][:200]}...\"\n",
    "            for i, src in enumerate(result.get('sources', []))\n",
    "        ])\n",
    "        \n",
    "        return (\n",
    "            result['subject'],\n",
    "            result['answer'],\n",
    "            None,  # TODO: Audio output\n",
    "            sources_text or \"Aucune source utilis√©e\"\n",
    "        )\n",
    "        \n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        error_msg = f\"‚ùå Erreur: {str(e)}\\n{traceback.format_exc()}\"\n",
    "        print(error_msg)\n",
    "        return \"\", error_msg, None, \"\"\n",
    "\n",
    "\n",
    "# Cr√©er l'interface Gradio\n",
    "with gr.Blocks(title=\"üé§ Agent Vocal IA - RAG Agentique\", theme=gr.themes.Soft()) as demo:\n",
    "    gr.Markdown(\"\"\"\n",
    "    # üé§ Agent Vocal IA avec RAG Agentique\n",
    "    ### 100% Local | Temps R√©el | Multi-Domaines (Pipecat Framework)\n",
    "    \n",
    "    **Mode 1 - Audio** : Enregistrez votre question (microphone)\n",
    "    **Mode 2 - Texte** : Tapez votre question directement\n",
    "    \n",
    "    **Domaines support√©s** : Math√©matiques üßÆ | Physique ‚öõÔ∏è | Anglais üá¨üáß\n",
    "    \"\"\")\n",
    "    \n",
    "    with gr.Tabs():\n",
    "        # Tab 1: Mode Audio\n",
    "        with gr.Tab(\"üé§ Mode Audio\"):\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=1):\n",
    "                    audio_input = gr.Audio(\n",
    "                        sources=[\"microphone\"],\n",
    "                        type=\"numpy\",\n",
    "                        label=\"üéôÔ∏è Enregistrez votre question\"\n",
    "                    )\n",
    "                    audio_btn = gr.Button(\"üöÄ Traiter l'audio\", variant=\"primary\", size=\"lg\")\n",
    "                    \n",
    "                with gr.Column(scale=1):\n",
    "                    audio_transcription = gr.Textbox(\n",
    "                        label=\"üìù Transcription\",\n",
    "                        lines=2,\n",
    "                        interactive=False\n",
    "                    )\n",
    "                    audio_subject = gr.Textbox(\n",
    "                        label=\"üéØ Domaine d√©tect√©\",\n",
    "                        interactive=False\n",
    "                    )\n",
    "                    audio_response = gr.Textbox(\n",
    "                        label=\"üí° R√©ponse de l'IA\",\n",
    "                        lines=5,\n",
    "                        interactive=False\n",
    "                    )\n",
    "                    audio_output = gr.Audio(\n",
    "                        label=\"üîä R√©ponse audio\",\n",
    "                        type=\"numpy\"\n",
    "                    )\n",
    "            \n",
    "            with gr.Accordion(\"üìö Sources RAG utilis√©es\", open=False):\n",
    "                audio_sources = gr.Markdown()\n",
    "            \n",
    "            audio_btn.click(\n",
    "                fn=process_audio,\n",
    "                inputs=[audio_input],\n",
    "                outputs=[audio_transcription, audio_subject, audio_response, audio_output, audio_sources]\n",
    "            )\n",
    "        \n",
    "        # Tab 2: Mode Texte\n",
    "        with gr.Tab(\"üí¨ Mode Texte\"):\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=1):\n",
    "                    text_input = gr.Textbox(\n",
    "                        label=\"üí¨ Votre question\",\n",
    "                        lines=3,\n",
    "                        placeholder=\"Ex: Comment r√©soudre x¬≤ + 2x - 8 = 0 ?\"\n",
    "                    )\n",
    "                    text_btn = gr.Button(\"üöÄ Poser la question\", variant=\"primary\", size=\"lg\")\n",
    "                    \n",
    "                with gr.Column(scale=1):\n",
    "                    text_subject = gr.Textbox(\n",
    "                        label=\"üéØ Domaine d√©tect√©\",\n",
    "                        interactive=False\n",
    "                    )\n",
    "                    text_response = gr.Textbox(\n",
    "                        label=\"üí° R√©ponse de l'IA\",\n",
    "                        lines=8,\n",
    "                        interactive=False\n",
    "                    )\n",
    "                    text_audio = gr.Audio(\n",
    "                        label=\"üîä R√©ponse audio (bient√¥t disponible)\",\n",
    "                        type=\"numpy\"\n",
    "                    )\n",
    "            \n",
    "            with gr.Accordion(\"üìö Sources RAG utilis√©es\", open=False):\n",
    "                text_sources = gr.Markdown()\n",
    "            \n",
    "            # Exemples\n",
    "            gr.Examples(\n",
    "                examples=[\n",
    "                    \"Comment r√©soudre une √©quation du second degr√© ?\",\n",
    "                    \"Explique-moi la premi√®re loi de Newton\",\n",
    "                    \"Comment conjuguer le verbe to be au pr√©sent ?\",\n",
    "                    \"Quelle est la formule de l'√©nergie cin√©tique ?\",\n",
    "                    \"C'est quoi un discriminant en math√©matiques ?\"\n",
    "                ],\n",
    "                inputs=text_input,\n",
    "                label=\"üí° Exemples de questions\"\n",
    "            )\n",
    "            \n",
    "            text_btn.click(\n",
    "                fn=process_text,\n",
    "                inputs=[text_input],\n",
    "                outputs=[text_subject, text_response, text_audio, text_sources]\n",
    "            )\n",
    "\n",
    "print(\"‚úÖ Interface Gradio cr√©√©e avec 2 modes (Audio + Texte)!\")\n",
    "print(\"=\" * 70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42ea248",
   "metadata": {},
   "source": [
    "## üöÄ √âtape 9 : Lancement de l'Application\n",
    "\n",
    "Lancez l'interface Gradio et testez l'agent vocal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4a292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ Lancement de l'application...\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nüì± L'interface va s'ouvrir dans quelques secondes...\")\n",
    "print(\"üí° Utilisez le microphone pour poser vos questions!\")\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "# Lancer l'application\n",
    "demo.launch(\n",
    "    share=True,  # Cr√©er un lien public partageable\n",
    "    debug=True,\n",
    "    show_error=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
