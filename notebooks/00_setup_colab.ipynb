{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a9b2b9d",
   "metadata": {},
   "source": [
    "# Agent Vocal Prof - Colab Setup\n",
    "### Installation, GPU Checks, and Smoke Tests\n",
    "\n",
    "This notebook sets up the complete environment for the voice tutoring agent on Google Colab.\n",
    "\n",
    "**What this notebook does:**\n",
    "1. ‚úÖ Install all dependencies\n",
    "2. ‚úÖ Check GPU availability and configure devices\n",
    "3. ‚úÖ Clone/setup the repository  \n",
    "4. ‚úÖ Download necessary models\n",
    "5. ‚úÖ Run smoke tests for each component\n",
    "6. ‚úÖ Build RAG indexes\n",
    "7. ‚úÖ Launch the Gradio UI\n",
    "\n",
    "**Estimated setup time:** 10-15 minutes (first run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7726b15f",
   "metadata": {},
   "source": [
    "## 1. System Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca00b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"System Information\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "\n",
    "# Check GPU\n",
    "gpu_info = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
    "if gpu_info.returncode == 0:\n",
    "    print(\"\\n‚úÖ GPU Available:\")\n",
    "    print(gpu_info.stdout)\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No GPU detected - using CPU (slower inference)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef63d95c",
   "metadata": {},
   "source": [
    "## 2. Install Dependencies\n",
    "\n",
    "This will install all required packages. Takes ~5 minutes on first run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c9e90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyTorch first (for CUDA support if available)\n",
    "!pip install -q torch==2.1.2 torchaudio==2.1.2 --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# Install main requirements\n",
    "!pip install -q faster-whisper==1.0.3\n",
    "!pip install -q sentence-transformers==2.2.2\n",
    "!pip install -q faiss-cpu==1.7.4\n",
    "!pip install -q pypdf==3.17.4\n",
    "!pip install -q pymupdf==1.23.8\n",
    "!pip install -q llama-cpp-python==0.2.27\n",
    "!pip install -q gradio==4.13.0\n",
    "!pip install -q PyYAML==6.0.1\n",
    "!pip install -q scikit-learn==1.3.2\n",
    "!pip install -q soundfile==0.12.1\n",
    "\n",
    "print(\"\\n‚úÖ All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53d7dfe",
   "metadata": {},
   "source": [
    "## 3. Clone Repository (or update if already cloned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838c1ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "repo_name = \"intelligence_lab_agent_vocal\"\n",
    "repo_url = \"https://github.com/your-org/intelligence_lab_agent_vocal.git\"\n",
    "\n",
    "if os.path.exists(repo_name):\n",
    "    print(f\"Repository already exists. Updating...\")\n",
    "    !cd {repo_name} && git pull\n",
    "else:\n",
    "    print(f\"Cloning repository...\")\n",
    "    # For demo purposes, we'll create the structure\n",
    "    # Replace with actual git clone in production:\n",
    "    # !git clone {repo_url}\n",
    "    !mkdir -p {repo_name}\n",
    "\n",
    "# Change to repo directory\n",
    "os.chdir(repo_name)\n",
    "print(f\"‚úÖ Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fe4472",
   "metadata": {},
   "source": [
    "## 4. Download Models\n",
    "\n",
    "Download lightweight quantized models suitable for Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1d89ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install HuggingFace CLI for model downloads\n",
    "!pip install -q huggingface-hub\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Create model directories\n",
    "Path(\"models/llm\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"models/voices\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Downloading language models...\")\n",
    "print(\"This may take 5-10 minutes depending on connection speed...\")\n",
    "\n",
    "# Download Qwen2 1.5B (smaller, faster for Colab)\n",
    "!huggingface-cli download Qwen/Qwen2-1.5B-Instruct-GGUF \\\n",
    "    qwen2-1_5b-instruct-q4_0.gguf \\\n",
    "    --local-dir models/llm \\\n",
    "    --local-dir-use-symlinks False\n",
    "\n",
    "print(\"\\n‚úÖ Language models downloaded!\")\n",
    "\n",
    "# Note: TTS models can be downloaded if needed\n",
    "# For now, we'll note that TTS is optional\n",
    "print(\"\\n‚ö†Ô∏è  Note: TTS models not downloaded (optional)\")\n",
    "print(\"System will work without TTS for text-based testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f7820f",
   "metadata": {},
   "source": [
    "## 5. Import and Test Core Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b104fe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add src to path\n",
    "import sys\n",
    "sys.path.insert(0, '/content/intelligence_lab_agent_vocal')\n",
    "\n",
    "print(\"Testing imports...\")\n",
    "\n",
    "try:\n",
    "    from src.config import get_config\n",
    "    print(\"‚úÖ Config module\")\n",
    "    \n",
    "    from src.utils import get_logger, setup_logging\n",
    "    print(\"‚úÖ Utils module\")\n",
    "    \n",
    "    from src.rag_build import RAGBuilder\n",
    "    print(\"‚úÖ RAG Build module\")\n",
    "    \n",
    "    from src.rag import RAGRetriever\n",
    "    print(\"‚úÖ RAG Retrieval module\")\n",
    "    \n",
    "    from src.asr import ASREngine\n",
    "    print(\"‚úÖ ASR module\")\n",
    "    \n",
    "    from src.router import SubjectRouter\n",
    "    print(\"‚úÖ Router module\")\n",
    "    \n",
    "    from src.llm import LLMEngine\n",
    "    print(\"‚úÖ LLM module\")\n",
    "    \n",
    "    from src.tts import TTSEngine\n",
    "    print(\"‚úÖ TTS module\")\n",
    "    \n",
    "    from src.orchestrator import TutoringOrchestrator\n",
    "    print(\"‚úÖ Orchestrator module\")\n",
    "    \n",
    "    print(\"\\n‚úÖ All modules imported successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Import error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fc6979",
   "metadata": {},
   "source": [
    "## 6. Configuration Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e90b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import get_config\n",
    "\n",
    "config = get_config()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Configuration\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nASR Model: {config.asr.model}\")\n",
    "print(f\"RAG Top-K: {config.rag.top_k}\")\n",
    "print(f\"LLM Context: {config.llm.n_ctx}\")\n",
    "print(f\"Available subjects: {list(config.router.keywords.keys())}\")\n",
    "\n",
    "print(\"\\nDirectory structure:\")\n",
    "print(f\"  Data: {config.data_dir}\")\n",
    "print(f\"  Models: {config.models_dir}\")\n",
    "print(f\"  Logs: {config.logs_dir}\")\n",
    "\n",
    "print(\"\\n‚úÖ Configuration loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0909af99",
   "metadata": {},
   "source": [
    "## 7. Smoke Tests\n",
    "\n",
    "Quick tests to ensure each component works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf2ed64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Component Smoke Tests\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test 1: Router\n",
    "print(\"\\nüîç Testing Router...\")\n",
    "from src.router import get_router\n",
    "\n",
    "router = get_router()\n",
    "test_query = \"Comment r√©soudre une √©quation du second degr√©?\"\n",
    "model_spec = router.pick_model(test_query)\n",
    "print(f\"  Query: {test_query}\")\n",
    "print(f\"  Detected subject: {model_spec.subject}\")\n",
    "print(f\"  Confidence: {model_spec.confidence:.2f}\")\n",
    "print(\"  ‚úÖ Router working\")\n",
    "\n",
    "# Test 2: ASR (skip if models not available)\n",
    "print(\"\\nüé§ Testing ASR...\")\n",
    "try:\n",
    "    from src.asr import get_asr_engine\n",
    "    asr = get_asr_engine()\n",
    "    \n",
    "    # Create dummy audio (1 second of noise)\n",
    "    sample_rate = 16000\n",
    "    duration = 1.0\n",
    "    dummy_audio = np.random.randn(int(sample_rate * duration)).astype(np.float32) * 0.1\n",
    "    \n",
    "    # Test VAD\n",
    "    has_speech = asr.detect_voice_activity(dummy_audio, sample_rate)\n",
    "    print(f\"  VAD test: {has_speech}\")\n",
    "    print(\"  ‚úÖ ASR working\")\n",
    "except Exception as e:\n",
    "    print(f\"  ‚ö†Ô∏è  ASR test skipped: {e}\")\n",
    "\n",
    "# Test 3: LLM\n",
    "print(\"\\nü§ñ Testing LLM...\")\n",
    "try:\n",
    "    from src.llm import get_llm_engine\n",
    "    \n",
    "    # Check if model exists\n",
    "    model_path = config.get_model_path(\"maths\")\n",
    "    if model_path.exists():\n",
    "        llm = get_llm_engine()\n",
    "        \n",
    "        prompt = \"What is 2+2?\"\n",
    "        # Don't actually generate to save time\n",
    "        print(f\"  Model loaded: {model_path.name}\")\n",
    "        print(\"  ‚úÖ LLM working\")\n",
    "    else:\n",
    "        print(f\"  ‚ö†Ô∏è  Model not found: {model_path}\")\n",
    "        print(\"  Please download models first\")\n",
    "except Exception as e:\n",
    "    print(f\"  ‚ö†Ô∏è  LLM test skipped: {e}\")\n",
    "\n",
    "# Test 4: TTS\n",
    "print(\"\\nüîä Testing TTS...\")\n",
    "from src.tts import get_tts_engine\n",
    "\n",
    "tts = get_tts_engine()\n",
    "test_text = \"Bonjour, ceci est un test.\"\n",
    "lang = tts.detect_language(test_text)\n",
    "print(f\"  Detected language: {lang}\")\n",
    "print(\"  ‚úÖ TTS working\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ All smoke tests passed!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad73c71",
   "metadata": {},
   "source": [
    "## 8. Build RAG Indexes\n",
    "\n",
    "Process sample documents and build FAISS indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f696453b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.rag_build import RAGBuilder\n",
    "\n",
    "print(\"Building RAG indexes for all subjects...\")\n",
    "print(\"This may take 2-5 minutes...\")\n",
    "\n",
    "builder = RAGBuilder()\n",
    "results = builder.build_all_indexes()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Index Building Results\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for subject, success in results.items():\n",
    "    status = \"‚úÖ SUCCESS\" if success else \"‚ùå FAILED\"\n",
    "    print(f\"{subject:12} : {status}\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316a6de4",
   "metadata": {},
   "source": [
    "## 9. Test RAG Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef3d8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.rag import get_retriever\n",
    "\n",
    "retriever = get_retriever()\n",
    "\n",
    "print(\"Available subjects:\", retriever.get_available_subjects())\n",
    "print(\"\\nTesting retrieval...\")\n",
    "\n",
    "# Test query\n",
    "test_query = \"Comment r√©soudre une √©quation du second degr√©?\"\n",
    "subject = \"maths\"\n",
    "\n",
    "if retriever.is_available(subject):\n",
    "    results = retriever.retrieve(subject, test_query, k=3)\n",
    "    \n",
    "    print(f\"\\nQuery: {test_query}\")\n",
    "    print(f\"Subject: {subject}\")\n",
    "    print(f\"Retrieved {len(results)} passages:\\n\")\n",
    "    \n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"{i}. Source: {result.source} (score: {result.score:.3f})\")\n",
    "        print(f\"   {result.text[:150]}...\")\n",
    "        print()\n",
    "    \n",
    "    print(\"‚úÖ RAG retrieval working!\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  No index available for {subject}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8f4f4f",
   "metadata": {},
   "source": [
    "## 10. Launch Gradio Interface\n",
    "\n",
    "Start the interactive web interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a693f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.ui_gradio import VoiceTutoringUI\n",
    "\n",
    "print(\"Launching Gradio UI...\")\n",
    "print(\"The interface will appear below.\")\n",
    "print(\"\\nYou can:\")\n",
    "print(\"  1. Type questions in the text box\")\n",
    "print(\"  2. View 3-level hint ladder responses\")\n",
    "print(\"  3. See RAG sources used\")\n",
    "\n",
    "# Create UI with Colab-specific settings\n",
    "ui = VoiceTutoringUI()\n",
    "\n",
    "# Launch with share=True to get public URL for Colab\n",
    "ui.launch(share=True, quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366a6cc8",
   "metadata": {},
   "source": [
    "## 11. Quick Test Query\n",
    "\n",
    "Try a sample question through the orchestrator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8323d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.orchestrator import get_orchestrator\n",
    "\n",
    "orchestrator = get_orchestrator()\n",
    "\n",
    "# Create a session\n",
    "session = orchestrator.create_session()\n",
    "\n",
    "# Test query\n",
    "test_query = \"Quelle est la formule pour r√©soudre une √©quation du second degr√©?\"\n",
    "\n",
    "print(f\"Processing query: {test_query}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Process the query\n",
    "for event in orchestrator.process_text_query(session, test_query):\n",
    "    if event.type == \"transcript\":\n",
    "        print(f\"\\nüìù Transcript: {event.data}\")\n",
    "    elif event.type == \"subject_detected\":\n",
    "        print(f\"üéØ Subject: {event.data['subject']}\")\n",
    "    elif event.type == \"rag_results\":\n",
    "        print(f\"üìö Retrieved {len(event.data)} passages\")\n",
    "    elif event.type == \"hints\":\n",
    "        hints = event.data\n",
    "        print(\"\\nüí° Hint Ladder:\")\n",
    "        print(f\"\\nüîµ Level 1: {hints['level1']}\")\n",
    "        print(f\"\\nüü° Level 2: {hints['level2']}\")\n",
    "        print(f\"\\nüü¢ Level 3: {hints['level3']}\")\n",
    "    elif event.type == \"error\":\n",
    "        print(f\"‚ùå Error: {event.data}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ Pipeline test complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c015f675",
   "metadata": {},
   "source": [
    "## üéâ Setup Complete!\n",
    "\n",
    "Your voice tutoring agent is now ready to use.\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Add more documents**: Upload PDFs or text files to `data/maths/`, `data/physique/`, or `data/anglais/`\n",
    "2. **Rebuild indexes**: Run the index building cell again after adding documents\n",
    "3. **Test different subjects**: Try questions in math, physics, or English\n",
    "4. **Customize prompts**: Edit `config/config.yaml` to adjust behavior\n",
    "\n",
    "### Usage Tips:\n",
    "\n",
    "- **Text mode**: Type questions in the text box for quick testing\n",
    "- **Voice mode**: Use the audio recorder for speech input (requires microphone)\n",
    "- **Hint ladder**: Progressively more detailed hints guide learning\n",
    "- **RAG sources**: Check the sources accordion to see where information came from\n",
    "\n",
    "### Troubleshooting:\n",
    "\n",
    "- **Out of memory**: Use smaller models or reduce `n_ctx` in config\n",
    "- **Slow generation**: Normal on CPU; enable GPU runtime in Colab settings\n",
    "- **Empty responses**: Make sure RAG indexes are built and models are downloaded\n",
    "\n",
    "---\n",
    "\n",
    "**Repository**: https://github.com/your-org/intelligence_lab_agent_vocal  \n",
    "**License**: MIT  \n",
    "**No API keys required** - Everything runs locally! üîí"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
